{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import scripts.functions as f\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Working directory\n",
    "wkdir = '/Users/Marianne/Dropbox (Personlig)/DTU/9. semester/02456_Deep_learning/project/results/'\n",
    "\n",
    "# Parameters\n",
    "ws = 20\n",
    "d_ws = 'after'\n",
    "bs = 256\n",
    "emb = 2\n",
    "check = 20\n",
    "post_fix = '_{0}_{1}_lr001_em{2}'.format(d_ws, ws, emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20, 'padding': 0}\n"
     ]
    }
   ],
   "source": [
    "# Load word2idx\n",
    "word2idx = torch.load(wkdir+'checkpoints/word2idx.pt')\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'A', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'K', 10: 'L', 11: 'M', 12: 'N', 13: 'P', 14: 'Q', 15: 'R', 16: 'S', 17: 'T', 18: 'V', 19: 'W', 20: 'Y', 0: 'padding'}\n"
     ]
    }
   ],
   "source": [
    "# Save idx2word\n",
    "idx2word = {value: key for key, value in word2idx.items()}\n",
    "print(idx2word)\n",
    "torch.save(idx2word, wkdir+'checkpoints/idx2word.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_data = f.DataLoader()\n",
    "test_data.load_corpus(path='data/proteins.test.txt')\n",
    "\n",
    "# Make context pairs for validation data\n",
    "test_data.make_context_pairs(window_size=ws, padding=True, direction=d_ws)\n",
    "\n",
    "# Convert to numpy\n",
    "test_data.words_to_index(word2idx=word2idx)\n",
    "\n",
    "# After data has been loaded it is good to check what is looks like. \n",
    "print('Number of test samples:\\t', test_data.context_array[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make batches\n",
    "test = data_utils.TensorDataset(torch.from_numpy(test_data.context_array[0]), \n",
    "                                torch.from_numpy(test_data.context_array[1]))\n",
    "load_test = data_utils.DataLoader(test, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up neural net\n",
    "check = torch.load(wkdir+'checkpoints/check' + str(check) + post_fix + '.pt', map_location='cpu')\n",
    "net = f.cbow(vocab_size=len(word2idx), embedding_dim=emb, padding=True)\n",
    "net.load_state_dict(check['model_state_dict'])\n",
    "epoch = check['epoch']\n",
    "\n",
    "# Set criterion \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up to use GPU if available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is available\n",
    "if use_cuda:\n",
    "    print('# Converting network to cuda-enabled')\n",
    "    net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on test set\n",
    "test_acc, test_loss = [], []\n",
    "\n",
    "### Evaluation ###\n",
    "net.eval()\n",
    "\n",
    "test_preds, test_targs = [], []\n",
    "test_losses, test_accs, test_lengths = 0, 0, 0\n",
    "examples, n_examples = [], 5\n",
    "\n",
    "# Print running \n",
    "pbar_test = tqdm(load_test, position=0)\n",
    "pbar_test.set_description(\"[Epoch {}, test]\".format(epoch+1))\n",
    "\n",
    "for i, (inputs, labels) in enumerate(pbar_test):\n",
    "    #print('Batch {0}/{1}'.format(i+1, len(load_test)))\n",
    "    n_samples = inputs.shape[0]\n",
    "\n",
    "    # Convert targets and input to cuda if available\n",
    "    if use_cuda: \n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    # Get predictions\n",
    "    output = net(inputs)\n",
    "    preds = torch.max(input=output, dim=1)[1]\n",
    "\n",
    "    if use_cuda: \n",
    "        preds = preds.data.cpu().numpy()\n",
    "    else: \n",
    "        preds = preds.data.numpy()\n",
    "\n",
    "    # Calculate validation loss\n",
    "    test_losses += criterion(output, labels).item() * n_samples\n",
    "    test_accs += f.accuracy(y_true=labels, y_pred=output) * n_samples\n",
    "    test_lengths += n_samples\n",
    "\n",
    "    # Save predictions and labels\n",
    "    test_preds += preds.tolist()\n",
    "    test_targs += labels.tolist()\n",
    "\n",
    "    # Save example inputs\n",
    "    if len(examples) < n_examples: \n",
    "        for n in range(n_examples):\n",
    "            examples.append([inputs[n], labels[n].item(), preds[n].item()])\n",
    "    \n",
    "    # Print percentage run\n",
    "    pbar_test.set_postfix(loss=test_losses/test_lengths, perp=np.exp(test_losses/test_lengths), acc=test_accs/test_lengths)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results of evaluation\n",
    "print('# Epoch %2i, TEST: loss=%f, perp=%f, acc=%f\\n' % (epoch+1, test_losses/test_lengths, \n",
    "                                                         np.exp(test_losses/test_lengths), \n",
    "                                                         test_accs/test_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
