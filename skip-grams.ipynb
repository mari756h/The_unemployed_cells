{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "The Penn Treebank datafiles are given in the urls below, where we have three different datasets: train, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.train.txt',\n",
    "        'https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.valid.txt',\n",
    "        'https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.test.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_table(urls[0], header=None)\n",
    "df_valid = pd.read_table(urls[1], header=None)\n",
    "df_test = pd.read_table(urls[2], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(df, sep=None, stats=False):\n",
    "    \"\"\"\n",
    "    Build the vocabulary given a data set consisting of sentences.\n",
    "    \n",
    "    Attributes:\n",
    "        data: data set with sentences\n",
    "        sep: seperator of words, default is None meaning split on every whitespace. \n",
    "             See help for string.split for more info.\n",
    "        stats: print statistics of input df\n",
    "    \"\"\"\n",
    "    # extract words\n",
    "    corpus = [x.split(sep) for x in df[0]]\n",
    "    \n",
    "    # error check that all sentences have been extracted\n",
    "    assert len(corpus) == df.shape[0]\n",
    "    \n",
    "    words = [y for x in corpus for y in x]    \n",
    "    \n",
    "    # unique words\n",
    "    vocab = list(set(words))\n",
    "    \n",
    "    # idx2word\n",
    "    \n",
    "    # word2idx\n",
    "    \n",
    "    if stats:\n",
    "        print(\"Number of sentences:\", df.shape[0], len(corpus))\n",
    "        print(\"Total number of words given:\", len(words))\n",
    "        print(\"Unique number of words given:\", len(vocab))\n",
    "        print(\"\")\n",
    "    return corpus, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train df: <class 'pandas.core.frame.DataFrame'> (42068, 1)\n",
      "Number of sentences: 42068 42068\n",
      "Total number of words given: 887521\n",
      "Unique number of words given: 9999\n",
      "\n",
      "Valid df: <class 'pandas.core.frame.DataFrame'> (3370, 1)\n",
      "Number of sentences: 3370 3370\n",
      "Total number of words given: 70390\n",
      "Unique number of words given: 6021\n",
      "\n",
      "Test df: <class 'pandas.core.frame.DataFrame'> (3761, 1)\n",
      "Number of sentences: 3761 3761\n",
      "Total number of words given: 78669\n",
      "Unique number of words given: 6048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train df:\", type(df_train), df_train.shape)\n",
    "train_vocab = build_vocabulary(df_train, stats=True)\n",
    "\n",
    "print(\"Valid df:\", type(df_valid), df_valid.shape)\n",
    "valid_vocab = build_vocabulary(df_valid, stats=True)\n",
    "\n",
    "print(\"Test df:\", type(df_test), df_test.shape)\n",
    "test_vocab = build_vocabulary(df_test, stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = urlopen(urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for line in train_data:\n",
    "    lines += [line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42068"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
