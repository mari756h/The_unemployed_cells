{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Bag-of-Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training CBoW\n",
    "The CBoW model has been implemented to run through command line with the following flags used in the run below: \n",
    "* *-train* and *-val* is the path to the training and validation data, respectively. \n",
    "* *-d* needs a string denoting the direction of the text window, which can be 'before', 'after' or 'both' for the models $p\\left(y_t|y_{t-c}\\right)$, $p\\left(y_t|y_{t+c}\\right)$ and $p\\left(y_t|y_{t-c}^{t+c}\\right)$, respectively. \n",
    "* *-pad* will store True and enable padding to be used in the model. \n",
    "* *-ws* is an integer and sets the window size, $c$. \n",
    "* *-embed* is an integer that sets the number of embedding dimensions. \n",
    "* *-b* is an integer that sets the batch size. \n",
    "* *-lr* needs a float and sets the learning rate for the model. \n",
    "* *-e* is an integer and sets the number of iterations or epochs for the model to run. \n",
    "* *-f* requires a string that will be used as postfix for all output files. \n",
    "\n",
    "Additional option flags include: \n",
    "* *-r* is the path to a saved checkpoint of the model, which enables resuming training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set flags and parameters\n",
    "tr = 'data/proteins.train.txt'\n",
    "v = 'data/proteins.val.txt'\n",
    "ws = 5\n",
    "d_ws = 'both'\n",
    "bs = 256\n",
    "emb = 2\n",
    "post_fix = '_{0}_{1}_lr001_em{2}'.format(d_ws, ws, emb)\n",
    "\n",
    "# Working directory, where output files will be saved\n",
    "wkdir = 'data/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CBoW model through command line\n",
    "!python CBoWscripts/main_CBoW_aa.py -train $tr -val $v -d $d_ws -pad -ws $ws -b $bs -f $post_fix -lr 0.001 -e 50 -embed $emb -wd $wkdir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program above will output the following files: \n",
    "* Checkpoints containing model details that can be loaded for testing or if training is resmed with *-r*. These are stored as .pt files. \n",
    "* Log files with epoch, loss, perplexity and accuracy. \n",
    "* The performance plot for the current number of epochs if traning is not interrupted prematurely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import CBoW_scripts.functions as f\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Set best epoch\n",
    "check = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20, 'padding': 0}\n"
     ]
    }
   ],
   "source": [
    "# Load word2idx (was created during training)\n",
    "word2idx = torch.load('data/word2idx.pt')\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading corpus...\n",
      "\tDone\n",
      "\n",
      "# Making context pairs...\n",
      "\tDone\n",
      "\n",
      "# Converting words to indices...\n",
      "(19153517, 10)\n",
      "\tDone\n",
      "\n",
      "Number of test samples:\t (19153517, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_data = f.DataLoader()\n",
    "test_data.load_corpus(path='data/proteins.test.txt')\n",
    "\n",
    "# Make context pairs for validation data\n",
    "test_data.make_context_pairs(window_size=ws, padding=True, direction=d_ws)\n",
    "\n",
    "# Convert to numpy\n",
    "test_data.words_to_index(word2idx=word2idx)\n",
    "\n",
    "# After data has been loaded it is good to check what is looks like. \n",
    "print('Number of test samples:\\t', test_data.context_array[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make batches\n",
    "test = data_utils.TensorDataset(torch.from_numpy(test_data.context_array[0]), \n",
    "                                torch.from_numpy(test_data.context_array[1]))\n",
    "load_test = data_utils.DataLoader(test, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up to use GPU if available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow(\n",
      "  (embeddings): Embedding(21, 2, padding_idx=0)\n",
      "  (linear_out): Linear(in_features=2, out_features=21, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load net class\n",
    "net = f.cbow(vocab_size=len(word2idx), embedding_dim=emb, padding=True)\n",
    "\n",
    "# If GPU is available\n",
    "if use_cuda:\n",
    "    print('# Converting network to cuda-enabled')\n",
    "    net.cuda()\n",
    "    loc_map = None\n",
    "else: \n",
    "    loc_map='cpu'\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up neural net\n",
    "net_path = wkdir+'check' + str(check) + post_fix + '.pt'\n",
    "check = torch.load(net_path, map_location=loc_map)\n",
    "net.load_state_dict(check['model_state_dict'])\n",
    "epoch = check['epoch']\n",
    "\n",
    "# Set criterion \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 50, test]:  29%|██▉       | 21919/74819 [02:49<06:37, 133.25it/s, acc=0.101, loss=2.88, perp=17.8]"
     ]
    }
   ],
   "source": [
    "# Run model on test set\n",
    "test_acc, test_loss = [], []\n",
    "\n",
    "### Evaluation ###\n",
    "net.eval()\n",
    "\n",
    "test_preds, test_targs = [], []\n",
    "test_losses, test_accs, test_lengths = 0, 0, 0\n",
    "examples, n_examples = [], 5\n",
    "\n",
    "# Print running \n",
    "pbar_test = tqdm(load_test, position=0)\n",
    "pbar_test.set_description(\"[Epoch {}, test]\".format(epoch+1))\n",
    "\n",
    "for i, (inputs, labels) in enumerate(pbar_test):\n",
    "    #print('Batch {0}/{1}'.format(i+1, len(load_test)))\n",
    "    n_samples = inputs.shape[0]\n",
    "\n",
    "    # Convert targets and input to cuda if available\n",
    "    if use_cuda: \n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    # Get predictions\n",
    "    output = net(inputs)\n",
    "    preds = torch.max(input=output, dim=1)[1]\n",
    "\n",
    "    if use_cuda: \n",
    "        preds = preds.data.cpu().numpy()\n",
    "    else: \n",
    "        preds = preds.data.numpy()\n",
    "\n",
    "    # Calculate validation loss\n",
    "    test_losses += criterion(output, labels).item() * n_samples\n",
    "    test_accs += f.accuracy(y_true=labels, y_pred=output) * n_samples\n",
    "    test_lengths += n_samples\n",
    "\n",
    "    # Save predictions and labels\n",
    "    test_preds += preds.tolist()\n",
    "    test_targs += labels.tolist()\n",
    "\n",
    "    # Save example inputs\n",
    "    if len(examples) < n_examples: \n",
    "        for n in range(n_examples):\n",
    "            examples.append([inputs[n], labels[n].item(), preds[n].item()])\n",
    "    \n",
    "    # Print percentage run\n",
    "    pbar_test.set_postfix(loss=test_losses/test_lengths, perp=np.exp(test_losses/test_lengths), acc=test_accs/test_lengths)\n",
    "print('\\n### Test completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results of evaluation\n",
    "print('# Epoch %2i, TEST: loss=%f, perp=%f, acc=%f\\n' % (epoch+1, test_losses/test_lengths, \n",
    "                                                         np.exp(test_losses/test_lengths), \n",
    "                                                         test_accs/test_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples of predictions\n",
    "print('# Input | Label | Prediction\\n')\n",
    "for ex in examples: \n",
    "    i, l, p = ex\n",
    "    print(i + ' | ' + l + ' | ' + p + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
