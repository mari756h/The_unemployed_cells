{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import functions as f\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Working directory\n",
    "wkdir = '/Users/Marianne/Dropbox (Personlig)/DTU/9. semester/02456_Deep_learning/project/results/'\n",
    "\n",
    "# Parameters\n",
    "ws = 5\n",
    "d_ws = 'after'\n",
    "bs = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20, 'padding': 0}\n"
     ]
    }
   ],
   "source": [
    "# Load word2idx\n",
    "word2idx = torch.load(wkdir+'word2idx.pt')\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading corpus...\n",
      "\tDone\n",
      "\n",
      "# Making context pairs...\n",
      "\tDone\n",
      "\n",
      "# Converting words to indices...\n",
      "(19153517, 5)\n",
      "\tDone\n",
      "\n",
      "Number of test samples:\t (19153517, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_data = f.DataLoader()\n",
    "test_data.load_corpus(path='data/proteins.test.txt')\n",
    "\n",
    "# Make context pairs for validation data\n",
    "test_data.make_context_pairs(window_size=ws, padding=True, direction=d_ws)\n",
    "\n",
    "# Convert to numpy\n",
    "test_data.words_to_index(word2idx=word2idx)\n",
    "\n",
    "# After data has been loaded it is good to check what is looks like. \n",
    "print('Number of test samples:\\t', test_data.context_array[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make batches\n",
    "test = data_utils.TensorDataset(torch.from_numpy(test_data.context_array[0]), \n",
    "                                torch.from_numpy(test_data.context_array[1]))\n",
    "load_test = data_utils.DataLoader(test, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up neural net\n",
    "check = torch.load(wkdir+'check7_' + d_ws + '_no_'+ str(ws) +'_em10.pt', map_location='cpu')\n",
    "net = f.cbow(vocab_size=len(word2idx), embedding_dim=10, padding=True)\n",
    "net.load_state_dict(check['model_state_dict'])\n",
    "epoch = check['epoch']\n",
    "\n",
    "# Set criterion \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up to use GPU if available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow(\n",
      "  (embeddings): Embedding(21, 10, padding_idx=0)\n",
      "  (linear_out): Linear(in_features=10, out_features=21, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# If GPU is available\n",
    "if use_cuda:\n",
    "    print('# Converting network to cuda-enabled')\n",
    "    net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7, test]: 100%|██████████| 149637/149637 [12:03<00:00, 206.94it/s, acc=0.104, loss=2.88, perp=17.8]\n"
     ]
    }
   ],
   "source": [
    "# Run model on test set\n",
    "test_acc, test_loss = [], []\n",
    "\n",
    "### Evaluation ###\n",
    "net.eval()\n",
    "\n",
    "test_preds, test_targs = [], []\n",
    "test_losses, test_accs, test_lengths = 0, 0, 0\n",
    "examples, n_examples = [], 5\n",
    "\n",
    "# Print running \n",
    "pbar_test = tqdm(load_test, position=0)\n",
    "pbar_test.set_description(\"[Epoch {}, test]\".format(epoch+1))\n",
    "\n",
    "for i, (inputs, labels) in enumerate(pbar_test):\n",
    "    #print('Batch {0}/{1}'.format(i+1, len(load_test)))\n",
    "    n_samples = inputs.shape[0]\n",
    "\n",
    "    # Convert targets and input to cuda if available\n",
    "    if use_cuda: \n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    # Get predictions\n",
    "    output = net(inputs)\n",
    "    preds = torch.max(input=output, dim=1)[1]\n",
    "\n",
    "    if use_cuda: \n",
    "        preds = preds.data.cpu().numpy()\n",
    "    else: \n",
    "        preds = preds.data.numpy()\n",
    "\n",
    "    # Calculate validation loss\n",
    "    test_losses += criterion(output, labels).item() * n_samples\n",
    "    test_accs += f.accuracy(y_true=labels, y_pred=output) * n_samples\n",
    "    test_lengths += n_samples\n",
    "\n",
    "    # Save predictions and labels\n",
    "    test_preds += preds.tolist()\n",
    "    test_targs += labels.tolist()\n",
    "\n",
    "    # Save example inputs\n",
    "    if len(examples) < n_examples: \n",
    "        for n in range(n_examples):\n",
    "            examples.append([inputs[n], labels[n].item(), preds[n].item()])\n",
    "    \n",
    "    # Print percentage run\n",
    "    pbar_test.set_postfix(loss=test_losses/test_lengths, perp=np.exp(test_losses/test_lengths), acc=test_accs/test_lengths)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch  7, TEST: loss=2.877850, perp=17.776008, acc=0.104179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show results of evaluation\n",
    "print('# Epoch %2i, TEST: loss=%f, perp=%f, acc=%f\\n' % (epoch+1, test_losses/test_lengths, \n",
    "                                                         np.exp(test_losses/test_lengths), \n",
    "                                                         test_accs/test_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
