{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hb__jPG-w2ee"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "#from os.path import exists\n",
    "#from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "#platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "#cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "#accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "\n",
    "#!pip3 install https://github.com/chengs/tqdm/archive/colab.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 868431,
     "status": "ok",
     "timestamp": 1544001291288,
     "user": {
      "displayName": "Marianne Helenius",
      "photoUrl": "https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg",
      "userId": "02929369287881856704"
     },
     "user_tz": -60
    },
    "id": "wwifFHGsxup1",
    "outputId": "cd80a03c-00fd-4b87-8959-427e1b3041e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-92267515-5c9d-48d3-b35a-6989945b0f67\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-92267515-5c9d-48d3-b35a-6989945b0f67\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving proteins.train.txt to proteins.train.txt\n"
     ]
    }
   ],
   "source": [
    "# Upload local data files\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acqV7S8vwu6-"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "import numpy as np\n",
    "#np.random.seed(seed)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "#torch.manual_seed(seed)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "#from IPython.display import clear_output\n",
    "\n",
    "# To print running \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7RHUsPycwu7D"
   },
   "outputs": [],
   "source": [
    "# General parameters \n",
    "pad = True  # Padding\n",
    "ws = 1      # Window_size\n",
    "bs = 128    # Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XX3Jpx5Bwu7K"
   },
   "source": [
    "# Data loading\n",
    "The Penn Treebank datafiles are given in the urls below, where we have three different datasets: train, validation and test. Data was downloaded from [train](https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.train.txt), [validation](https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.valid.txt) and [test](https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.test.txt). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cU0GOIy1wu7L"
   },
   "outputs": [],
   "source": [
    "# Data loader class\n",
    "class DataLoader: \n",
    "    def __init__(self):\n",
    "        self.corpus = []\n",
    "    \n",
    "    # Load words\n",
    "    def load_corpus(self, path): \n",
    "        print('# Loading corpus...')\n",
    "        with open(path, 'r') as infile: \n",
    "            pbar_fileload = tqdm(infile, position=0)\n",
    "            #pbar_fileload.set_description()\n",
    "            for line in pbar_fileload: \n",
    "                line = line[:-1].split()\n",
    "                self.corpus.append(line)\n",
    "        print('\\tDone\\n')\n",
    "    \n",
    "    # Make dict\n",
    "    def count_corpus(self, padding=True, verbose=False): \n",
    "        print('# Building vocabulary...')\n",
    "        # Count occurrences\n",
    "        unique, counts = np.unique(np.array([item for sublist in self.corpus for item in sublist]), return_counts=True)\n",
    "        self.corpus_counts = dict(zip(unique, counts))\n",
    "\n",
    "        if verbose: \n",
    "            for v, k in sorted(zip(counts, unique), reverse=True): \n",
    "                print('Key is \"{0}\" with count {1}'.format(k, v))\n",
    "\n",
    "        # Build vocabulary\n",
    "        if padding: \n",
    "            indices = list(range(1,len(unique)+1))\n",
    "            self.word_to_idx = dict(zip(sorted(unique), indices))\n",
    "            #self.word_to_idx = {word: i+1 for i, word in enumerate(self.corpus_counts.keys())}\n",
    "            self.word_to_idx['padding'] = 0\n",
    "        else: \n",
    "            indices = list(range(len(unique)))\n",
    "            self.word_to_idx = dict(zip(sorted(unique), indices))\n",
    "            #self.word_to_idx = {word: i for i, word in enumerate(self.corpus_counts.keys())}\n",
    "        \n",
    "        # Make reverse dict\n",
    "        self.idx_to_word = {w: idx for idx, w in self.word_to_idx.items()}\n",
    "        \n",
    "        print('\\tDone\\n')\n",
    "            \n",
    "    # Function to make context pairs\n",
    "    def make_context_pairs(self, window_size=2, padding=True): \n",
    "        print('# Making context pairs...') \n",
    "        self.window_size = window_size\n",
    "        \n",
    "        # Set percentage bar \n",
    "        pbar_corpus = tqdm(self.corpus, position=0)\n",
    "        del self.corpus\n",
    "        \n",
    "        # Run through each sample\n",
    "        self.word_data = []\n",
    "        for line in pbar_corpus: \n",
    "            if padding: \n",
    "                # Add padding corresponding to the size of the window on either side\n",
    "                padding = ['padding']*window_size\n",
    "                line = padding+line+padding\n",
    "\n",
    "            # Make contexts\n",
    "            for i in range(window_size, len(line) - window_size):\n",
    "                context, c = [], -window_size\n",
    "                while c <= window_size:\n",
    "                    if c != 0: \n",
    "                        context.append(line[i+c])\n",
    "                    c += 1\n",
    "                self.word_data.append((context, line[i]))\n",
    "        print('\\tDone\\n')\n",
    "\n",
    "    # Convert word_data to numpy array tuples\n",
    "    def words_to_index(self, word2idx):\n",
    "        if hasattr(self, 'window_size'): \n",
    "            print('# Converting words to indices...')\n",
    "            \n",
    "            # Pre-allocate\n",
    "            data = np.empty((len(self.word_data), self.window_size*2), dtype=int)\n",
    "            labels = np.empty((len(self.word_data)), dtype=int)\n",
    "            print(data.shape)\n",
    "            \n",
    "            # Run through context pairs and fill arrays\n",
    "            i = 0\n",
    "            for d, l in self.word_data: \n",
    "                data[i, :] = np.array([word2idx[w] for w in d])\n",
    "                labels[i,] = word2idx[l]\n",
    " \n",
    "                i += 1\n",
    "                \n",
    "            # Save as tuple\n",
    "            self.context_array = (data, labels)\n",
    "            \n",
    "            # Remove word_data\n",
    "            del self.word_data\n",
    "            \n",
    "            print('\\tDone\\n')\n",
    "        else: \n",
    "            print('# Make context pairs, first!')\n",
    "            sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XcYlNqt5wu7O"
   },
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCg9GyMswu7O"
   },
   "outputs": [],
   "source": [
    "# Get training data\n",
    "train_data = DataLoader()\n",
    "#train_data.load_corpus(path='proteins.train.txt')\n",
    "#train_data.count_corpus(padding=pad)\n",
    "\n",
    "# Make context pairs for training data\n",
    "#train_data.make_context_pairs(window_size=ws, padding=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3853,
     "status": "ok",
     "timestamp": 1544001360436,
     "user": {
      "displayName": "Marianne Helenius",
      "photoUrl": "https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg",
      "userId": "02929369287881856704"
     },
     "user_tz": -60
    },
    "id": "p4VsSdQOhtlr",
    "outputId": "ef553e54-ba1e-47ed-91ce-cb7b1d932c05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4100it [00:00, 36792.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "126795it [00:03, 40012.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDone\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.load_corpus(path='data/proteins.train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14333,
     "status": "ok",
     "timestamp": 1544001384701,
     "user": {
      "displayName": "Marianne Helenius",
      "photoUrl": "https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg",
      "userId": "02929369287881856704"
     },
     "user_tz": -60
    },
    "id": "k3CUToZThuHC",
    "outputId": "32844c9c-c697-4731-95ef-99da057109d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Building vocabulary...\n",
      "\tDone\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.count_corpus(padding=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 158144,
     "status": "ok",
     "timestamp": 1544001568975,
     "user": {
      "displayName": "Marianne Helenius",
      "photoUrl": "https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg",
      "userId": "02929369287881856704"
     },
     "user_tz": -60
    },
    "id": "Q0VWiwYehuez",
    "outputId": "6d29a469-d88f-41bb-bd38-8b915106dabf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/126795 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Making context pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126795/126795 [05:23<00:00, 392.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDone\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Make context pairs for training data\n",
    "train_data.make_context_pairs(window_size=ws, padding=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1544001578900,
     "user": {
      "displayName": "Marianne Helenius",
      "photoUrl": "https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg",
      "userId": "02929369287881856704"
     },
     "user_tz": -60
    },
    "id": "P7Tbee91wu7R",
    "outputId": "5c645956-8de9-41a7-b43f-87d083489f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63785764\n",
      "['padding', 'A'] M\n",
      "['M', 'N'] A\n",
      "['A', 'E'] N\n",
      "['N', 'V'] E\n",
      "['E', 'I'] V\n",
      "['V', 'L'] I\n",
      "['I', 'L'] L\n",
      "['L', 'D'] L\n",
      "['L', 'F'] D\n",
      "['D', 'W'] F\n"
     ]
    }
   ],
   "source": [
    "# Check word contexts\n",
    "word_sum = len(train_data.word_data)\n",
    "print(word_sum)\n",
    "for context, word in train_data.word_data[:10]: \n",
    "    print(context, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8684,
     "status": "ok",
     "timestamp": 1543930956576,
     "user": {
      "displayName": "Marianne Helenius",
      "photoUrl": "https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg",
      "userId": "02929369287881856704"
     },
     "user_tz": -60
    },
    "id": "u1XFY6txwu7W",
    "outputId": "3ced869b-a3f8-43e5-cefa-2bd231dcaa37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Converting words to indices...\n",
      "(63785764, 2)\n",
      "\tDone\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy\n",
    "train_data.words_to_index(word2idx=train_data.word_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n06GwQTawu7a"
   },
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vr707Tjdwu7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4044it [00:00, 39317.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19852it [00:00, 42539.78it/s]\n",
      "  1%|          | 161/19852 [00:00<00:12, 1577.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDone\n",
      "\n",
      "# Making context pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19852/19852 [00:14<00:00, 1380.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDone\n",
      "\n",
      "# Converting words to indices...\n",
      "(9572660, 2)\n",
      "\tDone\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get validation data\n",
    "valid_data = DataLoader()\n",
    "valid_data.load_corpus(path='data/proteins.val.txt')\n",
    "\n",
    "# Make context pairs for validation data\n",
    "valid_data.make_context_pairs(window_size=ws, padding=pad)\n",
    "\n",
    "# Convert to numpy\n",
    "valid_data.words_to_index(word2idx=train_data.word_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y7WntR1Owu7e"
   },
   "source": [
    "After data has been loaded it is good to check what is looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7246,
     "status": "ok",
     "timestamp": 1543930957022,
     "user": {
      "displayName": "Marianne Helenius",
      "photoUrl": "https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg",
      "userId": "02929369287881856704"
     },
     "user_tz": -60
    },
    "id": "E5F5CfjTwu7g",
    "outputId": "9968fe2d-59d6-4d78-b21f-95f5954f4958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:\t (63785764, 2)\n",
      "Number of validation samples:\t (9572660, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Number of training samples:\\t', train_data.context_array[0].shape)\n",
    "print('Number of validation samples:\\t', valid_data.context_array[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "HmvZVmN0wu7j"
   },
   "source": [
    "# CBOW class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGR_X4ZDwu7k"
   },
   "outputs": [],
   "source": [
    "class cbow(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, window_size, embedding_dim=2, n_hid=(128*2, 128), padding=True):\n",
    "        super(cbow, self).__init__()\n",
    "        # num_embeddings is the number of words in your train, val and test set\n",
    "        # embedding_dim is the dimension of the word vectors you are using\n",
    "        if padding: \n",
    "            self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, \n",
    "                                          padding_idx=0)\n",
    "        else: \n",
    "            self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, \n",
    "                                          padding_idx=None)\n",
    "        \n",
    "        #self.linear1 = nn.Linear(in_features=window_size * embedding_dim, out_features=n_hid, bias=True) # with order\n",
    "        \n",
    "        #self.linear1 = nn.Linear(in_features=embedding_dim, out_features=n_hid, bias=True) # one hidden\n",
    "        #self.linear2 = nn.Linear(in_features=n_hid, out_features=vocab_size, bias=False) # one hidden\n",
    "        \n",
    "        #self.linear1 = nn.Linear(in_features=embedding_dim, out_features=n_hid[0], bias=True) # two hidden\n",
    "        #self.linear2 = nn.Linear(in_features=n_hid[0], out_features=n_hid[1], bias=True)\n",
    "        #self.linear3 = nn.Linear(in_features=n_hid[1], out_features=vocab_size, bias=False)\n",
    "        \n",
    "        self.linear_out = nn.Linear(in_features=embedding_dim, out_features=vocab_size, bias=False)\n",
    "        \n",
    "        self.window = window_size\n",
    "        self.embed_dim = embedding_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs)\n",
    "        \n",
    "        # To not care about the order of the words we take the mean of the time dimension\n",
    "        means = torch.mean(embeds, dim=1)\n",
    "        \n",
    "        # To care about order, use: embeds.view((-1, self.window*self.embed_dim))\n",
    "        #print(embeds.shape, embeds.view((-1, self.window*self.embed_dim)).shape)\n",
    "        #out = F.relu(self.linear1(means))\n",
    "        #out = self.linear2(out)\n",
    "        \n",
    "        #out = F.relu(self.linear2(out))\n",
    "        #out = self.linear3(out)\n",
    "        \n",
    "        #probs = F.log_softmax(out, dim=1)\n",
    "        probs = F.log_softmax(self.linear_out(means), dim=1)\n",
    "        \n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLqnAbvSwu7p"
   },
   "outputs": [],
   "source": [
    "# Estimate performance\n",
    "def accuracy(y_true, y_pred):\n",
    "    # Make y_pred for the word with max probability\n",
    "    values, indices = torch.max(input=y_pred, dim=1)\n",
    "    \n",
    "    # Check if indices match\n",
    "    check = torch.eq(indices, y_true)\n",
    "    \n",
    "    # Estimate accuracy\n",
    "    acc = check.sum().item()/len(check)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5726,
     "status": "ok",
     "timestamp": 1543930957223,
     "user": {
      "displayName": "Marianne Helenius",
      "photoUrl": "https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg",
      "userId": "02929369287881856704"
     },
     "user_tz": -60
    },
    "id": "WI1VFsxAAK67",
    "outputId": "b96331ce-80fd-4aa8-931e-3e6bab115217"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up to use GPU if available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NwotDxKosfvw"
   },
   "source": [
    "# Mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7oH3xJawu7t"
   },
   "outputs": [],
   "source": [
    "# Pytorch batch_loader\n",
    "train = data_utils.TensorDataset(torch.from_numpy(train_data.context_array[0]), torch.from_numpy(train_data.context_array[1]))\n",
    "load_train = data_utils.DataLoader(train, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid = data_utils.TensorDataset(torch.from_numpy(valid_data.context_array[0]), torch.from_numpy(valid_data.context_array[1]))\n",
    "load_valid = data_utils.DataLoader(valid, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "yBi2s-k3wu7s"
   },
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xsdLfWCnwu7v"
   },
   "outputs": [],
   "source": [
    "# Set loss, model and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = cbow(vocab_size=len(train_data.word_to_idx), window_size=ws*2, embedding_dim=300, n_hid=264, padding=pad)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-5)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3139,
     "status": "ok",
     "timestamp": 1543930968846,
     "user": {
      "displayName": "Marianne Helenius",
      "photoUrl": "https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg",
      "userId": "02929369287881856704"
     },
     "user_tz": -60
    },
    "id": "Me_gre-5Lq7M",
    "outputId": "4a5e1af3-947e-4f64-a1e2-36c504def6bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow(\n",
      "  (embeddings): Embedding(21, 300, padding_idx=0)\n",
      "  (linear_out): Linear(in_features=300, out_features=21, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# If GPU is available\n",
    "if use_cuda:\n",
    "    print('# Converting network to cuda-enabled')\n",
    "    net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2831,
     "status": "ok",
     "timestamp": 1543930968848,
     "user": {
      "displayName": "Marianne Helenius",
      "photoUrl": "https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg",
      "userId": "02929369287881856704"
     },
     "user_tz": -60
    },
    "id": "X1dfb5ZEwu72",
    "outputId": "b5f0d12c-a780-40ad-d8d1-8df821231aaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata, target = next(iter(load_train))\\nif use_cuda: \\n  data = data.cuda().long()\\n  target = target.cuda().long()\\n  output = net(data)\\n  loss = criterion(output, target)\\nelse: \\n  output = net(data.long())\\n\\n# Caculate loss\\nloss = criterion(output, target)\\n\\n# Estimate accuracy\\nacc = accuracy(y_true=target, y_pred=output)\\n\\nprint('Loss:', loss.item(), '\\tAccuracy:', acc)\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the network \n",
    "\"\"\"\n",
    "data, target = next(iter(load_train))\n",
    "if use_cuda: \n",
    "  data = data.cuda().long()\n",
    "  target = target.cuda().long()\n",
    "  output = net(data)\n",
    "  loss = criterion(output, target)\n",
    "else: \n",
    "  output = net(data.long())\n",
    "\n",
    "# Caculate loss\n",
    "loss = criterion(output, target)\n",
    "\n",
    "# Estimate accuracy\n",
    "acc = accuracy(y_true=target, y_pred=output)\n",
    "\n",
    "print('Loss:', loss.item(), '\\tAccuracy:', acc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fc1nYFIUwu8A"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53621,
     "status": "error",
     "timestamp": 1543934726718,
     "user": {
      "displayName": "Marianne Helenius",
      "photoUrl": "https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg",
      "userId": "02929369287881856704"
     },
     "user_tz": -60
    },
    "id": "Dtlq2Pwrwu8H",
    "outputId": "1c13a7c1-5ab8-403e-944a-058c8362c70d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1, train]: 100%|██████████| 498327/498327 [1:02:44<00:00, 132.36it/s, acc=0.0966, loss=2.9, perp=18.1] \n",
      "[Epoch 1, valid]: 100%|██████████| 74787/74787 [1:10:04<00:00, 17.79it/s, acc=0.0999, loss=2.89, perp=17.9]     \n",
      "[Epoch 2, train]: 100%|██████████| 498327/498327 [1:06:48<00:00, 124.31it/s, acc=0.101, loss=2.88, perp=17.9]\n",
      "[Epoch 2, valid]: 100%|██████████| 74787/74787 [1:14:45<00:00, 16.67it/s, acc=0.1, loss=2.89, perp=17.9]       \n",
      "[Epoch 3, train]:  21%|██        | 105662/498327 [15:01<1:01:01, 107.23it/s, acc=0.102, loss=2.88, perp=17.9]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a539a0a53307>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lists and parameters\n",
    "examples, n_examples = [], 5\n",
    "losses = []\n",
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "iter_count = [0]\n",
    "max_epochs = 10\n",
    "verbose = False\n",
    "\n",
    "# Run through epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Print running \n",
    "    pbar_train = tqdm(load_train, position=0)\n",
    "    pbar_valid = tqdm(load_valid, position=0)\n",
    "    pbar_train.set_description(\"[Epoch {}, train]\".format(epoch+1))\n",
    "    pbar_valid.set_description(\"[Epoch {}, valid]\".format(epoch+1))\n",
    "    \n",
    "    ### Train ###\n",
    "    current_loss = 0\n",
    "    net.train()\n",
    "    train_lengths, train_accs = 0, 0\n",
    "    for i, (inputs, labels) in enumerate(pbar_train):\n",
    "        n_samples = inputs.shape[0]\n",
    "        \n",
    "        # Convert targets and input to cuda if available\n",
    "        if use_cuda: \n",
    "          inputs = inputs.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        # Zero gradient\n",
    "        net.zero_grad()\n",
    "\n",
    "        # Run the forward pass, getting probabilities over next words\n",
    "        probs = net(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(probs, labels)\n",
    "\n",
    "        # Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        current_loss += loss.item() * n_samples\n",
    "        \n",
    "        # Accuracy\n",
    "        train_accs += accuracy(y_true=labels, y_pred=probs) * n_samples \n",
    "        train_lengths += n_samples\n",
    "        \n",
    "        # Print percentage run\n",
    "        pbar_train.set_postfix(loss=current_loss/train_lengths, perp=np.exp(current_loss/train_lengths), acc=train_accs/train_lengths)\n",
    "    \n",
    "    train_loss.append(current_loss/train_lengths)\n",
    "    train_acc.append(train_accs/train_lengths)\n",
    "\n",
    "    \n",
    "    ### Evaluation ###\n",
    "    net.eval()\n",
    "    \n",
    "    val_preds, val_targs = [], []\n",
    "    val_losses, val_accs, val_lengths = 0, 0, 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(pbar_valid):\n",
    "        n_samples = inputs.shape[0]\n",
    "      \n",
    "        # Convert targets and input to cuda if available\n",
    "        if use_cuda: \n",
    "          inputs = inputs.cuda()\n",
    "          labels = labels.cuda()\n",
    "        \n",
    "        # Get predictions\n",
    "        output = net(inputs)\n",
    "        preds = torch.max(input=output, dim=1)[1]\n",
    "        \n",
    "        if use_cuda: \n",
    "           preds = preds.data.cpu().numpy()\n",
    "        else: \n",
    "           preds = preds.data.numpy()\n",
    "        \n",
    "        # Calculate validation loss\n",
    "        val_losses += criterion(output, labels).item() * n_samples\n",
    "        val_accs += accuracy(y_true=labels, y_pred=output) * n_samples\n",
    "        val_lengths += n_samples\n",
    "        \n",
    "        # Save predictions and labels\n",
    "        val_preds += preds.tolist()\n",
    "        val_targs += labels.tolist()\n",
    "        \n",
    "        # Save example inputs\n",
    "        if len(examples) < n_examples: \n",
    "            for n in range(n_examples):\n",
    "              examples.append([inputs[n], labels[n].item(), preds[n].item()])\n",
    "        \n",
    "        # Print percentage run\n",
    "        pbar_valid.set_postfix(loss=val_losses/val_lengths, perp=np.exp(val_losses/val_lengths), acc=val_accs/val_lengths)\n",
    "\n",
    "    # Calculate accuracy and loss\n",
    "    valid_loss.append(val_losses/val_lengths)\n",
    "    valid_acc.append(val_accs/val_lengths)\n",
    "    \n",
    "    # Show results of evaluation\n",
    "    #if epoch % 1 == 0:\n",
    "    #print(\"### Epoch %2i:\\tTrain loss %f, Train perplexity %f, Train acc %f\\n\\t\\tValid loss %f, Valid perplexity %f, Valid acc %f\\n\" % (\n",
    "    #        epoch+1, train_loss[-1], train_perp, train_acc_cur, valid_loss[-1], val_perp, valid_acc_cur))\n",
    "\n",
    "    # Show top N validation samples and their results\n",
    "    \"\"\"\n",
    "    print('# Predition examples: prediction | target | input')\n",
    "    for items in examples: \n",
    "      i, l, p = items\n",
    "\n",
    "      # Transform indices to words\n",
    "      input2word = [train_data.idx_to_word[e.item()] for e in i]\n",
    "      pred2word = train_data.idx_to_word[p]\n",
    "      targ2word = train_data.idx_to_word[l]\n",
    "      print('\\t', pred2word, '|', targ2word, '|', input2word)\n",
    "      #print(pred2word + ' | ' + input2word + ' | ' + str(input2word))\n",
    "    \"\"\"\n",
    "    #print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZ5myEw0Ry8S"
   },
   "outputs": [],
   "source": [
    "epoch = np.arange(max_epochs)\n",
    "fig, axes = plt.subplots(figsize=(2*7,7), ncols=2, nrows=1)\n",
    "ylabels = ['Loss', 'Accuracy']\n",
    "legends = [['Train loss', 'Valid loss'], ['Train Acc', 'Val Acc']]\n",
    "ydata = [[train_loss, valid_loss], [train_acc, valid_acc]]\n",
    "\n",
    "for i, ax in enumerate(fig.axes): \n",
    "  ax.plot(epoch, ydata[i][0], 'r', epoch, ydata[i][1], 'b')\n",
    "  ax.legend(legends[i])\n",
    "  ax.set_xlabel('Epochs')\n",
    "  ax.set_ylabel(ylabels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G3fgLIG5CjsU"
   },
   "source": [
    "# Test model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJu961xACoZ-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "vv1XlghOwu8a"
   },
   "source": [
    "# Notes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t2rx7OPCwu8c"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CBOW_no_order_proteins.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/mari756h/The_unemployed_cells/blob/master/continuous_bag_of_words.ipynb",
     "timestamp": 1542711419783
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
