{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CBOW_no_order_proteins.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/mari756h/The_unemployed_cells/blob/master/continuous_bag_of_words.ipynb","timestamp":1542711419783}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"hb__jPG-w2ee","colab_type":"code","colab":{}},"cell_type":"code","source":["# http://pytorch.org/\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n","\n","#!pip3 install https://github.com/chengs/tqdm/archive/colab.zip"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wwifFHGsxup1","colab_type":"code","outputId":"cd80a03c-00fd-4b87-8959-427e1b3041e3","executionInfo":{"status":"ok","timestamp":1544001291288,"user_tz":-60,"elapsed":868431,"user":{"displayName":"Marianne Helenius","photoUrl":"https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg","userId":"02929369287881856704"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["# Upload local data files\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-92267515-5c9d-48d3-b35a-6989945b0f67\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-92267515-5c9d-48d3-b35a-6989945b0f67\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving proteins.train.txt to proteins.train.txt\n"],"name":"stdout"}]},{"metadata":{"id":"acqV7S8vwu6-","colab_type":"code","colab":{}},"cell_type":"code","source":["seed = 42\n","import numpy as np\n","#np.random.seed(seed)\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import torch.utils.data as data_utils\n","#torch.manual_seed(seed)\n","\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","import sys\n","import os\n","#from IPython.display import clear_output\n","\n","# To print running \n","from tqdm import tqdm"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7RHUsPycwu7D","colab_type":"code","colab":{}},"cell_type":"code","source":["# General parameters \n","pad = True  # Padding\n","ws = 1      # Window_size\n","bs = 128    # Batch size"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XX3Jpx5Bwu7K","colab_type":"text"},"cell_type":"markdown","source":["# Data loading\n","The Penn Treebank datafiles are given in the urls below, where we have three different datasets: train, validation and test. Data was downloaded from [train](https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.train.txt), [validation](https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.valid.txt) and [test](https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.test.txt). "]},{"metadata":{"id":"cU0GOIy1wu7L","colab_type":"code","colab":{}},"cell_type":"code","source":["# Data loader class\n","class DataLoader: \n","    def __init__(self):\n","        self.corpus = []\n","    \n","    # Load words\n","    def load_corpus(self, path): \n","        print('# Loading corpus...')\n","        with open(path, 'r') as infile: \n","            pbar_fileload = tqdm(infile, position=0)\n","            #pbar_fileload.set_description()\n","            for line in pbar_fileload: \n","                line = line[:-1].split()\n","                self.corpus.append(line)\n","        print('\\tDone\\n')\n","    \n","    # Make dict\n","    def count_corpus(self, padding=True, verbose=False): \n","        print('# Building vocabulary...')\n","        # Count occurrences\n","        unique, counts = np.unique(np.array([item for sublist in self.corpus for item in sublist]), return_counts=True)\n","        self.corpus_counts = dict(zip(unique, counts))\n","\n","        if verbose: \n","            for v, k in sorted(zip(counts, unique), reverse=True): \n","                print('Key is \"{0}\" with count {1}'.format(k, v))\n","\n","        # Build vocabulary\n","        if padding: \n","            indices = list(range(1,len(unique)+1))\n","            self.word_to_idx = dict(zip(sorted(unique), indices))\n","            #self.word_to_idx = {word: i+1 for i, word in enumerate(self.corpus_counts.keys())}\n","            self.word_to_idx['padding'] = 0\n","        else: \n","            indices = list(range(len(unique)))\n","            self.word_to_idx = dict(zip(sorted(unique), indices))\n","            #self.word_to_idx = {word: i for i, word in enumerate(self.corpus_counts.keys())}\n","        \n","        # Make reverse dict\n","        self.idx_to_word = {w: idx for idx, w in self.word_to_idx.items()}\n","        \n","        print('\\tDone\\n')\n","            \n","    # Function to make context pairs\n","    def make_context_pairs(self, window_size=2, padding=True): \n","        print('# Making context pairs...') \n","        self.window_size = window_size\n","        \n","        # Set percentage bar \n","        pbar_corpus = tqdm(self.corpus, position=0)\n","        del self.corpus\n","        \n","        # Run through each sample\n","        self.word_data = []\n","        for line in pbar_corpus: \n","            if padding: \n","                # Add padding corresponding to the size of the window on either side\n","                padding = ['padding']*window_size\n","                line = padding+line+padding\n","\n","            # Make contexts\n","            for i in range(window_size, len(line) - window_size):\n","                context, c = [], -window_size\n","                while c <= window_size:\n","                    if c != 0: \n","                        context.append(line[i+c])\n","                    c += 1\n","                self.word_data.append((context, line[i]))\n","        print('\\tDone\\n')\n","\n","    # Convert word_data to numpy array tuples\n","    def words_to_index(self, word2idx):\n","        if hasattr(self, 'window_size'): \n","            print('# Converting words to indices...')\n","            \n","            # Pre-allocate\n","            data = np.empty((len(self.word_data), self.window_size*2), dtype=int)\n","            labels = np.empty((len(self.word_data)), dtype=int)\n","            print(data.shape)\n","            \n","            # Run through context pairs and fill arrays\n","            i = 0\n","            for d, l in self.word_data: \n","                data[i, :] = np.array([word2idx[w] for w in d])\n","                labels[i,] = word2idx[l]\n"," \n","                i += 1\n","                \n","            # Save as tuple\n","            self.context_array = (data, labels)\n","            print('\\tDone\\n')\n","        else: \n","            print('# Make context pairs, first!')\n","            sys.exit(1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XcYlNqt5wu7O","colab_type":"text"},"cell_type":"markdown","source":["## Training data"]},{"metadata":{"id":"aCg9GyMswu7O","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get training data\n","train_data = DataLoader()\n","#train_data.load_corpus(path='proteins.train.txt')\n","#train_data.count_corpus(padding=pad)\n","\n","# Make context pairs for training data\n","#train_data.make_context_pairs(window_size=ws, padding=pad)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"p4VsSdQOhtlr","colab_type":"code","outputId":"ef553e54-ba1e-47ed-91ce-cb7b1d932c05","executionInfo":{"status":"ok","timestamp":1544001360436,"user_tz":-60,"elapsed":3853,"user":{"displayName":"Marianne Helenius","photoUrl":"https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg","userId":"02929369287881856704"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["train_data.load_corpus(path='proteins.train.txt')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["5675it [00:00, 56748.57it/s]"],"name":"stderr"},{"output_type":"stream","text":["# Loading corpus...\n"],"name":"stdout"},{"output_type":"stream","text":["126795it [00:03, 38263.24it/s]"],"name":"stderr"},{"output_type":"stream","text":["\tDone\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"metadata":{"id":"k3CUToZThuHC","colab_type":"code","outputId":"32844c9c-c697-4731-95ef-99da057109d5","executionInfo":{"status":"ok","timestamp":1544001384701,"user_tz":-60,"elapsed":14333,"user":{"displayName":"Marianne Helenius","photoUrl":"https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg","userId":"02929369287881856704"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["train_data.count_corpus(padding=pad)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["# Building vocabulary...\n","\tDone\n","\n"],"name":"stdout"}]},{"metadata":{"id":"Q0VWiwYehuez","colab_type":"code","outputId":"6d29a469-d88f-41bb-bd38-8b915106dabf","executionInfo":{"status":"ok","timestamp":1544001568975,"user_tz":-60,"elapsed":158144,"user":{"displayName":"Marianne Helenius","photoUrl":"https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg","userId":"02929369287881856704"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["# Make context pairs for training data\n","train_data.make_context_pairs(window_size=ws, padding=pad)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/126795 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["# Making context pairs...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 126795/126795 [02:37<00:00, 806.02it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\tDone\n","\n"],"name":"stdout"}]},{"metadata":{"id":"P7Tbee91wu7R","colab_type":"code","outputId":"5c645956-8de9-41a7-b43f-87d083489f13","executionInfo":{"status":"ok","timestamp":1544001578900,"user_tz":-60,"elapsed":491,"user":{"displayName":"Marianne Helenius","photoUrl":"https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg","userId":"02929369287881856704"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["# Check word contexts\n","word_sum = len(train_data.word_data)\n","print(word_sum)\n","for context, word in train_data.word_data[:10]: \n","    print(context, word)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["63785764\n","['padding', 'A'] M\n","['M', 'N'] A\n","['A', 'E'] N\n","['N', 'V'] E\n","['E', 'I'] V\n","['V', 'L'] I\n","['I', 'L'] L\n","['L', 'D'] L\n","['L', 'F'] D\n","['D', 'W'] F\n"],"name":"stdout"}]},{"metadata":{"id":"u1XFY6txwu7W","colab_type":"code","outputId":"3ced869b-a3f8-43e5-cefa-2bd231dcaa37","executionInfo":{"status":"ok","timestamp":1543930956576,"user_tz":-60,"elapsed":8684,"user":{"displayName":"Marianne Helenius","photoUrl":"https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg","userId":"02929369287881856704"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["# Convert to numpy\n","train_data.words_to_index(word2idx=train_data.word_to_idx)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["# Converting words to indices...\n","(63785764, 2)\n"],"name":"stdout"}]},{"metadata":{"id":"n06GwQTawu7a","colab_type":"text"},"cell_type":"markdown","source":["## Validation data"]},{"metadata":{"id":"vr707Tjdwu7c","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get validation data\n","valid_data = DataLoader()\n","valid_data.load_corpus(path='proteins.valid.txt')\n","\n","# Make context pairs for validation data\n","valid_data.make_context_pairs(window_size=ws, padding=pad)\n","\n","# Convert to numpy\n","valid_data.words_to_index(word2idx=train_data.word_to_idx)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y7WntR1Owu7e","colab_type":"text"},"cell_type":"markdown","source":["After data has been loaded it is good to check what is looks like. "]},{"metadata":{"id":"E5F5CfjTwu7g","colab_type":"code","outputId":"9968fe2d-59d6-4d78-b21f-95f5954f4958","executionInfo":{"status":"ok","timestamp":1543930957022,"user_tz":-60,"elapsed":7246,"user":{"displayName":"Marianne Helenius","photoUrl":"https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg","userId":"02929369287881856704"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["print('Number of training samples:\\t', train_data.context_array[0].shape)\n","print('Number of validation samples:\\t', valid_data.context_array[0].shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of training samples:\t (887521, 8)\n","Number of validation samples:\t (70390, 8)\n"],"name":"stdout"}]},{"metadata":{"collapsed":true,"id":"HmvZVmN0wu7j","colab_type":"text"},"cell_type":"markdown","source":["# CBOW class"]},{"metadata":{"id":"BGR_X4ZDwu7k","colab_type":"code","colab":{}},"cell_type":"code","source":["class cbow(nn.Module):\n","\n","    def __init__(self, vocab_size, window_size, embedding_dim=2, n_hid=(128*2, 128), padding=True):\n","        super(cbow, self).__init__()\n","        # num_embeddings is the number of words in your train, val and test set\n","        # embedding_dim is the dimension of the word vectors you are using\n","        if padding: \n","            self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, \n","                                          padding_idx=0)\n","        else: \n","            self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, \n","                                          padding_idx=None)\n","        \n","        #self.linear1 = nn.Linear(in_features=window_size * embedding_dim, out_features=n_hid, bias=True) # with order\n","        \n","        #self.linear1 = nn.Linear(in_features=embedding_dim, out_features=n_hid, bias=True) # one hidden\n","        #self.linear2 = nn.Linear(in_features=n_hid, out_features=vocab_size, bias=False) # one hidden\n","        \n","        #self.linear1 = nn.Linear(in_features=embedding_dim, out_features=n_hid[0], bias=True) # two hidden\n","        #self.linear2 = nn.Linear(in_features=n_hid[0], out_features=n_hid[1], bias=True)\n","        #self.linear3 = nn.Linear(in_features=n_hid[1], out_features=vocab_size, bias=False)\n","        \n","        self.linear_out = nn.Linear(in_features=embedding_dim, out_features=vocab_size, bias=False)\n","        \n","        self.window = window_size\n","        self.embed_dim = embedding_dim\n","\n","    def forward(self, inputs):\n","        embeds = self.embeddings(inputs)\n","        \n","        # To not care about the order of the words we take the mean of the time dimension\n","        means = torch.mean(embeds, dim=1)\n","        \n","        # To care about order, use: embeds.view((-1, self.window*self.embed_dim))\n","        #print(embeds.shape, embeds.view((-1, self.window*self.embed_dim)).shape)\n","        #out = F.relu(self.linear1(means))\n","        #out = self.linear2(out)\n","        \n","        #out = F.relu(self.linear2(out))\n","        #out = self.linear3(out)\n","        \n","        #probs = F.log_softmax(out, dim=1)\n","        probs = F.log_softmax(self.linear_out(means), dim=1)\n","        \n","        return probs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RLqnAbvSwu7p","colab_type":"code","colab":{}},"cell_type":"code","source":["# Estimate performance\n","def accuracy(y_true, y_pred):\n","    # Make y_pred for the word with max probability\n","    values, indices = torch.max(input=y_pred, dim=1)\n","    \n","    # Check if indices match\n","    check = torch.eq(indices, y_true)\n","    \n","    # Estimate accuracy\n","    acc = check.sum().item()/len(check)\n","    return acc"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WI1VFsxAAK67","colab_type":"code","outputId":"b96331ce-80fd-4aa8-931e-3e6bab115217","executionInfo":{"status":"ok","timestamp":1543930957223,"user_tz":-60,"elapsed":5726,"user":{"displayName":"Marianne Helenius","photoUrl":"https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg","userId":"02929369287881856704"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Set up to use GPU if available\n","use_cuda = torch.cuda.is_available()\n","use_cuda"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"NwotDxKosfvw","colab_type":"text"},"cell_type":"markdown","source":["# Mini batches"]},{"metadata":{"id":"E7oH3xJawu7t","colab_type":"code","colab":{}},"cell_type":"code","source":["# Pytorch batch_loader\n","train = data_utils.TensorDataset(torch.from_numpy(train_data.context_array[0]), torch.from_numpy(train_data.context_array[1]))\n","load_train = data_utils.DataLoader(train, batch_size=bs, shuffle=True)\n","\n","valid = data_utils.TensorDataset(torch.from_numpy(valid_data.context_array[0]), torch.from_numpy(valid_data.context_array[1]))\n","load_valid = data_utils.DataLoader(valid, batch_size=bs, shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"collapsed":true,"id":"yBi2s-k3wu7s","colab_type":"text"},"cell_type":"markdown","source":["# Model parameters"]},{"metadata":{"id":"xsdLfWCnwu7v","colab_type":"code","colab":{}},"cell_type":"code","source":["# Set loss, model and optimizer\n","criterion = nn.CrossEntropyLoss()\n","net = cbow(vocab_size=len(train_data.word_to_idx), window_size=ws*2, embedding_dim=300, n_hid=264, padding=pad)\n","#optimizer = optim.Adam(net.parameters(), lr=0.01)\n","#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-5)\n","optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Me_gre-5Lq7M","colab_type":"code","outputId":"4a5e1af3-947e-4f64-a1e2-36c504def6bf","executionInfo":{"status":"ok","timestamp":1543930968846,"user_tz":-60,"elapsed":3139,"user":{"displayName":"Marianne Helenius","photoUrl":"https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg","userId":"02929369287881856704"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"cell_type":"code","source":["# If GPU is available\n","if use_cuda:\n","    print('# Converting network to cuda-enabled')\n","    net.cuda()\n","print(net)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["# Converting network to cuda-enabled\n","cbow(\n","  (embeddings): Embedding(10000, 300, padding_idx=0)\n","  (linear_out): Linear(in_features=300, out_features=10000, bias=False)\n",")\n"],"name":"stdout"}]},{"metadata":{"id":"X1dfb5ZEwu72","colab_type":"code","outputId":"b5f0d12c-a780-40ad-d8d1-8df821231aaa","executionInfo":{"status":"ok","timestamp":1543930968848,"user_tz":-60,"elapsed":2831,"user":{"displayName":"Marianne Helenius","photoUrl":"https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg","userId":"02929369287881856704"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["# Test the network \n","\"\"\"\n","data, target = next(iter(load_train))\n","if use_cuda: \n","  data = data.cuda().long()\n","  target = target.cuda().long()\n","  output = net(data)\n","  loss = criterion(output, target)\n","else: \n","  output = net(data.long())\n","\n","# Caculate loss\n","loss = criterion(output, target)\n","\n","# Estimate accuracy\n","acc = accuracy(y_true=target, y_pred=output)\n","\n","print('Loss:', loss.item(), '\\tAccuracy:', acc)\n","\"\"\""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ndata, target = next(iter(load_train))\\nif use_cuda: \\n  data = data.cuda().long()\\n  target = target.cuda().long()\\n  output = net(data)\\n  loss = criterion(output, target)\\nelse: \\n  output = net(data.long())\\n\\n# Caculate loss\\nloss = criterion(output, target)\\n\\n# Estimate accuracy\\nacc = accuracy(y_true=target, y_pred=output)\\n\\nprint('Loss:', loss.item(), '\\tAccuracy:', acc)\\n\""]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"Fc1nYFIUwu8A","colab_type":"text"},"cell_type":"markdown","source":["# Model training"]},{"metadata":{"scrolled":false,"id":"Dtlq2Pwrwu8H","colab_type":"code","outputId":"1c13a7c1-5ab8-403e-944a-058c8362c70d","executionInfo":{"status":"error","timestamp":1543934726718,"user_tz":-60,"elapsed":53621,"user":{"displayName":"Marianne Helenius","photoUrl":"https://lh3.googleusercontent.com/-9Mfpdx27BQM/AAAAAAAAAAI/AAAAAAAAAGU/-wUuZ6TnM8c/s64/photo.jpg","userId":"02929369287881856704"}},"colab":{"base_uri":"https://localhost:8080/","height":326}},"cell_type":"code","source":["# Lists and parameters\n","examples, n_examples = [], 5\n","losses = []\n","train_acc, train_loss = [], []\n","valid_acc, valid_loss = [], []\n","iter_count = [0]\n","max_epochs = 100\n","verbose = False\n","\n","# Run through epochs\n","for epoch in range(max_epochs):\n","    # Print running \n","    pbar_train = tqdm(load_train, position=0)\n","    pbar_valid = tqdm(load_valid, position=0)\n","    pbar_train.set_description(\"[Epoch {}, train]\".format(epoch+1))\n","    pbar_valid.set_description(\"[Epoch {}, valid]\".format(epoch+1))\n","    \n","    ### Train ###\n","    current_loss = 0\n","    net.train()\n","    train_lengths, train_accs = 0, 0\n","    for i, (inputs, labels) in enumerate(pbar_train):\n","        n_samples = inputs.shape[0]\n","        \n","        # Convert targets and input to cuda if available\n","        if use_cuda: \n","          inputs = inputs.cuda()\n","          labels = labels.cuda()\n","\n","        # Zero gradient\n","        net.zero_grad()\n","\n","        # Run the forward pass, getting probabilities over next words\n","        probs = net(inputs)\n","\n","        # Compute loss\n","        loss = criterion(probs, labels)\n","\n","        # Do the backward pass and update the gradient\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Get the Python number from a 1-element Tensor by calling tensor.item()\n","        current_loss += loss.item() * n_samples\n","        \n","        # Accuracy\n","        train_accs += accuracy(y_true=labels, y_pred=probs) * n_samples \n","        train_lengths += n_samples\n","        \n","        # Print percentage run\n","        pbar_train.set_postfix(loss=current_loss/train_lengths, perp=np.exp(current_loss/train_lengths), acc=train_accs/train_lengths)\n","    \n","    train_loss.append(current_loss/train_lengths)\n","    train_acc.append(train_accs/train_lengths)\n","\n","    \n","    ### Evaluation ###\n","    net.eval()\n","    \n","    val_preds, val_targs = [], []\n","    val_losses, val_accs, val_lengths = 0, 0, 0\n","\n","    for i, (inputs, labels) in enumerate(pbar_valid):\n","        n_samples = inputs.shape[0]\n","      \n","        # Convert targets and input to cuda if available\n","        if use_cuda: \n","          inputs = inputs.cuda()\n","          labels = labels.cuda()\n","        \n","        # Get predictions\n","        output = net(inputs)\n","        preds = torch.max(input=output, dim=1)[1]\n","        \n","        if use_cuda: \n","           preds = preds.data.cpu().numpy()\n","        else: \n","           preds = preds.data.numpy()\n","        \n","        # Calculate validation loss\n","        val_losses += criterion(output, labels).item() * n_samples\n","        val_accs += accuracy(y_true=labels, y_pred=output) * n_samples\n","        val_lengths += n_samples\n","        \n","        # Save predictions and labels\n","        val_preds += preds.tolist()\n","        val_targs += labels.tolist()\n","        \n","        # Save example inputs\n","        if len(examples) < n_examples: \n","            for n in range(n_examples):\n","              examples.append([inputs[n], labels[n].item(), preds[n].item()])\n","        \n","        # Print percentage run\n","        pbar_valid.set_postfix(loss=val_losses/val_lengths, perp=np.exp(val_losses/val_lengths), acc=val_accs/val_lengths)\n","\n","    # Calculate accuracy and loss\n","    valid_loss.append(val_losses/val_lengths)\n","    valid_acc.append(val_accs/val_lengths)\n","    \n","    # Show results of evaluation\n","    #if epoch % 1 == 0:\n","    #print(\"### Epoch %2i:\\tTrain loss %f, Train perplexity %f, Train acc %f\\n\\t\\tValid loss %f, Valid perplexity %f, Valid acc %f\\n\" % (\n","    #        epoch+1, train_loss[-1], train_perp, train_acc_cur, valid_loss[-1], val_perp, valid_acc_cur))\n","\n","    # Show top N validation samples and their results\n","    \"\"\"\n","    print('# Predition examples: prediction | target | input')\n","    for items in examples: \n","      i, l, p = items\n","\n","      # Transform indices to words\n","      input2word = [train_data.idx_to_word[e.item()] for e in i]\n","      pred2word = train_data.idx_to_word[p]\n","      targ2word = train_data.idx_to_word[l]\n","      print('\\t', pred2word, '|', targ2word, '|', input2word)\n","      #print(pred2word + ' | ' + input2word + ' | ' + str(input2word))\n","    \"\"\"\n","    #print('\\n')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[Epoch 1, train]: 100%|██████████| 6934/6934 [01:39<00:00, 69.42it/s, acc=0.096, loss=7.16, perp=1.28e+3]\n","[Epoch 1, valid]: 100%|██████████| 550/550 [01:44<00:00, 109.31it/s, acc=0.103, loss=6.72, perp=832]\n","[Epoch 2, train]: 100%|██████████| 6934/6934 [01:39<00:00, 69.44it/s, acc=0.105, loss=6.59, perp=730]\n","[Epoch 2, valid]: 100%|██████████| 550/550 [01:45<00:00,  5.24it/s, acc=0.107, loss=6.5, perp=664] \n","[Epoch 3, train]: 100%|██████████| 6934/6934 [01:40<00:00, 67.72it/s, acc=0.109, loss=6.4, perp=605]\n","[Epoch 3, valid]: 100%|██████████| 550/550 [01:45<00:00,  5.24it/s, acc=0.11, loss=6.38, perp=590] \n","[Epoch 4, train]: 100%|██████████| 6934/6934 [01:40<00:00, 69.54it/s, acc=0.113, loss=6.28, perp=535]\n","[Epoch 4, valid]: 100%|██████████| 550/550 [01:45<00:00,  5.22it/s, acc=0.112, loss=6.3, perp=545] \n","[Epoch 5, train]: 100%|██████████| 6934/6934 [01:39<00:00, 69.38it/s, acc=0.116, loss=6.19, perp=486]\n","[Epoch 5, valid]: 100%|██████████| 550/550 [01:45<00:00,  5.23it/s, acc=0.114, loss=6.24, perp=514] \n","[Epoch 6, train]: 100%|██████████| 6934/6934 [01:39<00:00, 69.80it/s, acc=0.119, loss=6.11, perp=449]\n","[Epoch 6, valid]: 100%|██████████| 550/550 [01:44<00:00, 112.00it/s, acc=0.118, loss=6.19, perp=489]\n","[Epoch 7, train]: 100%|██████████| 6934/6934 [01:37<00:00, 70.96it/s, acc=0.121, loss=6.04, perp=420]\n","[Epoch 7, valid]: 100%|██████████| 550/550 [01:42<00:00,  5.36it/s, acc=0.118, loss=6.15, perp=469] \n","[Epoch 8, train]: 100%|██████████| 6934/6934 [01:38<00:00, 70.63it/s, acc=0.124, loss=5.98, perp=395]\n","[Epoch 8, valid]: 100%|██████████| 550/550 [01:43<00:00,  5.34it/s, acc=0.121, loss=6.12, perp=453] \n","[Epoch 9, train]:  17%|█▋        | 1161/6934 [00:16<01:22, 69.63it/s, acc=0.124, loss=5.94, perp=379]"],"name":"stderr"},{"output_type":"stream","text":["Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"metadata":{"id":"FZ5myEw0Ry8S","colab_type":"code","colab":{}},"cell_type":"code","source":["epoch = np.arange(max_epochs)\n","fig, axes = plt.subplots(figsize=(2*7,7), ncols=2, nrows=1)\n","ylabels = ['Loss', 'Accuracy']\n","legends = [['Train loss', 'Valid loss'], ['Train Acc', 'Val Acc']]\n","ydata = [[train_loss, valid_loss], [train_acc, valid_acc]]\n","\n","for i, ax in enumerate(fig.axes): \n","  ax.plot(epoch, ydata[i][0], 'r', epoch, ydata[i][1], 'b')\n","  ax.legend(legends[i])\n","  ax.set_xlabel('Epochs')\n","  ax.set_ylabel(ylabels[i])\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G3fgLIG5CjsU","colab_type":"text"},"cell_type":"markdown","source":["# Test model on test set"]},{"metadata":{"id":"lJu961xACoZ-","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"collapsed":true,"id":"vv1XlghOwu8a","colab_type":"text"},"cell_type":"markdown","source":["# Notes "]},{"metadata":{"id":"t2rx7OPCwu8c","colab_type":"text"},"cell_type":"markdown","source":[""]}]}